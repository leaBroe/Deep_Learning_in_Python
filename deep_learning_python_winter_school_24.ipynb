{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leaBroe/Deep_Learning_in_Python/blob/main/deep_learning_python_winter_school_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Overview\n",
        "\n",
        "This is the project for the course \"Deep Learning in Python\" from the Machine Learning Winter School 2024 from the University of Fribourg.\n",
        "\n",
        "Authors:  \n",
        "Lea BrÃ¶nnimann lea.broennimann@unifr.ch (19-107-010)  \n",
        "Mohamed Mansour Faye mohamedmansour.faye@unifr.ch (19-505-197)  \n",
        "Laura Dekker laura.dekker@unifr.ch (22-112-346)  \n",
        "\n",
        "The code as well as some example texts to test the app can be found in the Github repo: [https://github.com/leaBroe/Deep_Learning_in_Python.git](https://github.com/leaBroe/Deep_Learning_in_Python.git)  \n",
        "\n",
        "\n",
        "**Abstract:**\n",
        "\n",
        "We have created an app that conducts a sentiment analysis over written text. This is a process where text is analyzed to assess its tone, whether it is more positive or negative. To be inclusive the app can also analyze text from other languages than English, because we included a translation model in it. The final product is the Gradio interface in which you can upload an image containing digital text. From this you will receive the translated text and the sentiment and emotion that are inferred to be contained in it. An app like this can be useful to bring across emotion in the digital world better. Almost everyone has had trouble reading between the lines of a text when deducing the emotion behind it. Another application of such a model can be found in AI customer service where an app like this can be used by an AI to provide more appropriate responses to its customers. A further application could be in more effective social media monitoring to make the job of social media moderators easier. Other applications could include analysing customer feedback. In addition, the entities are extracted from the text, which can be useful, for example, in quickly analysing annual reports from companies. All in all, enough reason to develop software that can analyze emotions and extract relevant entities in written text.\n",
        "\n",
        "### Model Card\n",
        "\n",
        "- **Model Details**: This app incorporates three different models in order to perform sentiment analysis from text images. We first use the python-tesseract OCR tool from the `pytesseract` package to extract text from images. We then perform sentiment analysis and topic classification using `distilbert-base-uncased-finetuned-sst-2-english`, which is available on Hugging Face. Because this model only works with english text, we also use the `m2m100_418M` model from Meta (also available on HuggingFace) to translate the input text when it is not in English.\n",
        "- **Data**: The distilbert SST2 model is based on the BERT transformer from Google, which was trained on large amounts of english text (from Wikipedia amongst others) in a self-supervised fashion. It was then fine-tuned on the Stanford Sentiment Treebank to enhance performance on sentiment analysis tasks.\n",
        "- **Performance**: The fine-tuned distilbert model achieves a good score of 91.3 on the GLUE benchmark, but as we will discuss later, might struggle with some specific subtasks/topics. The overall pipeline's performance also depends on the language of the input text. The Many-to-Many translation model used here doesn't perform as well when translating Wolof than when translating German, for example.\n",
        "- **Ethical Considerations**: Developers highlight the model producing biased predictions which affect underrepresented populations. As the SST 2 dataset was sourced from movie reviews on Rotten Tomatoes, many of the statements on which the fine-tuning is based on contain judgement on the way (American) movies in particular portray one topic or another, which might result in biased predictions.\n",
        "\n",
        "### Outlook\n",
        "\n",
        "Given an extra month, we might consider:\n",
        "\n",
        "- **Expanding Data Sources**: Including more diverse sources of images and text, such as news articles or blogs, to enrich the analysis.\n",
        "- **Model Fine-Tuning**: Fine-tuning the sentiment analysis model on a dataset specifically related to the specific user-case we are interested in. We could probably have used more advanced AI models such as a sentiment analysis model that works with any language or better translation models. But the ones we used now were quite easy to use and gave decent results.\n",
        "- **Feature Expansion**: Adding functionality to track sentiment trends over time, e.g. enabling longitudinal studies on public sentiment toward environmental issues.\n",
        "- **More Advanced Analyses**: For example, in order to better analyse the overall sentiment of customer feedback or trends in the perception of environmental issues, it would certainly be helpful if you could analyse a larger quantity of texts in parallel and, e.g. calculate the percentage of positive or negative feedback."
      ],
      "metadata": {
        "id": "hpA3aK4xlFtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13JEguyL3KZ0",
        "outputId": "1194a961-56f0-4121-f164-971547b9546d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract #!!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mGUxtgogA-e",
        "outputId": "f954aab4-a06b-4872-d378-2a0ad6f03133"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect #!!!"
      ],
      "metadata": {
        "id": "73oqyjjvtlF-",
        "outputId": "2c8e6f1a-836f-4851-d230-d4ece247d2a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio #!!!"
      ],
      "metadata": {
        "id": "6aP5zKCZsPVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3408cc9-2281-4d9b-c003-c14f6ecba1f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.21.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.110.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.12.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.12.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.36.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr #!!!\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "\n",
        "# Pipelines\n",
        "emotion_pipeline = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Your existing function for extracting text from an image file\n",
        "def extract_text_from_image(image_path):\n",
        "    from PIL import Image\n",
        "    import pytesseract\n",
        "    image = Image.open(image_path)\n",
        "    extracted_text = pytesseract.image_to_string(image)\n",
        "    return extracted_text.strip()\n",
        "\n",
        "\n",
        "from langdetect import detect\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "# Load your translation model and tokenizer\n",
        "model_name = \"facebook/m2m100_418M\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def translate_text_to_english(text):\n",
        "    # Detect the language of the input text\n",
        "    detected_lang = detect(text)\n",
        "    print(f\"Detected language: {detected_lang}\")  # For debugging\n",
        "\n",
        "    # Check if the detected language is English\n",
        "    if detected_lang == 'en':\n",
        "        return text, detected_lang  # Return the original text if it's already in English\n",
        "\n",
        "    # Specify the source language for the tokenizer; m2m100 uses language codes\n",
        "    tokenizer.src_lang = detected_lang\n",
        "\n",
        "    # Encode the text for the model\n",
        "    encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Generate translation tokens and decode them to text\n",
        "    # Note: forced_bos_token_id forces the model to translate to English\n",
        "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
        "    translated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "    return translated_text, detected_lang\n",
        "\n",
        "\n",
        "# Function to get sentiment from text\n",
        "def get_sentiment(text):\n",
        "    results = sentiment_pipeline(text)\n",
        "    return results\n",
        "\n",
        "# Function to get emotion from text\n",
        "def get_emotion(text):\n",
        "    results = emotion_pipeline(text)\n",
        "    return results\n",
        "\n",
        "# Function to extract named entities using spaCy\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Main processing function to integrate OCR, translation, sentiment and emotion analysis, and NER\n",
        "def process_image(image):\n",
        "    extracted_text = extract_text_from_image(image)\n",
        "    translated_text, detected_lang = translate_text_to_english(extracted_text)\n",
        "    sentiment_result = get_sentiment(translated_text)\n",
        "    emotion_result = get_emotion(translated_text)\n",
        "    entities = extract_entities(translated_text)  # Use spaCy to extract entities\n",
        "    entities_str = ', '.join([f\"{text} ({label})\" for text, label in entities])  # Format entities for display\n",
        "    return extracted_text, detected_lang, translated_text, sentiment_result, emotion_result, entities_str\n",
        "\n",
        "# Define Gradio interface\n",
        "iface = gr.Interface(fn=process_image,\n",
        "                     inputs=gr.Image(label=\"Upload Image\", type=\"filepath\"),\n",
        "                     outputs=[gr.Textbox(label=\"Extracted Text\"),\n",
        "                              gr.Textbox(label=\"Detected Language\"),\n",
        "                              gr.Textbox(label=\"Translated Text\"),\n",
        "                              gr.Textbox(label=\"Sentiment Analysis Result\"),\n",
        "                              gr.Textbox(label=\"Emotion Analysis Result\"),\n",
        "                              gr.Textbox(label=\"Extracted Entities\")],\n",
        "                     title=\"Image to Sentiment and Emotion Analysis\",\n",
        "                     description=\"Upload an image containing text, and the app will translate the text to English, then perform sentiment and emotion analysis and extract named entities.\")\n",
        "\n",
        "# Launch the app\n",
        "# debug=True\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "cM3F5f-c0uqi",
        "outputId": "460d130d-e8cf-4efc-92ce-6fc845df33d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://73a3bad08bfc5cec2b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://73a3bad08bfc5cec2b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2tD5buTgy3w"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}